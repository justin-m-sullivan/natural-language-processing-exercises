{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Exercises for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the inshorts article data, practice using the modeling tools for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Godrej, PwC, Deloitte India give extra offs to...</td>\n",
       "      <td>Several companies in India have been offering ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Gates' company Cascade transfers ₹13,300 ...</td>\n",
       "      <td>Bill Gates' Cascade Investment, a holding comp...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Infosys commits additional ₹100 crore for COVI...</td>\n",
       "      <td>Infosys has committed additional ₹100 crore fo...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China flight halt in India may hurt pharma sup...</td>\n",
       "      <td>The Indian Drug Manufacturers' Association (ID...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIL may soon fly in Israeli experts to install...</td>\n",
       "      <td>Reliance Industries has sought permission to f...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Godrej, PwC, Deloitte India give extra offs to...   \n",
       "1  Bill Gates' company Cascade transfers ₹13,300 ...   \n",
       "2  Infosys commits additional ₹100 crore for COVI...   \n",
       "3  China flight halt in India may hurt pharma sup...   \n",
       "4  RIL may soon fly in Israeli experts to install...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Several companies in India have been offering ...  business  \n",
       "1  Bill Gates' Cascade Investment, a holding comp...  business  \n",
       "2  Infosys has committed additional ₹100 crore fo...  business  \n",
       "3  The Indian Drug Manufacturers' Association (ID...  business  \n",
       "4  Reliance Industries has sought permission to f...  business  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acquire the data using the function from the acquire module\n",
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\", \"science\", \"world\"]\n",
    "news_df = acquire.get_all_news_articles(categories)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "news_df['clean'] = news_df['content'].apply(lambda x: prepare.remove_stopwords(prepare.tokenize(prepare.basic_clean(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>several companies india offering extra holiday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>bill gates ' cascade investment holding compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>infosys committed additional 100 crore covid19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>indian drug manufacturers ' association idma w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>reliance industries sought permission fly isra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                              clean\n",
       "0  business  several companies india offering extra holiday...\n",
       "1  business  bill gates ' cascade investment holding compan...\n",
       "2  business  infosys committed additional 100 crore covid19...\n",
       "3  business  indian drug manufacturers ' association idma w...\n",
       "4  business  reliance industries sought permission fly isra..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subset the data into a df with just the clean and category columns\n",
    "df = news_df[['category', 'clean']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to further clean up\n",
    "#def clean(text):\n",
    "#    'A simple function to cleanup text data'\n",
    "#    wnl = nltk.stem.WordNetLemmatizer()\n",
    "#    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "#    return [wnl.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breakdown words by the article category\n",
    "#biz_words = clean(' '.join(df.clean[df.category == 'business']))\n",
    "#sports_words = clean(' '.join(df.clean[df.category == 'sports']))\n",
    "#tech_words = clean(' '.join(df.clean[df.category == 'technology']))\n",
    "#ent_words = clean(' '.join(df.clean[df.category == 'entertainment']))\n",
    "#science_words = clean(' '.join(df.clean[df.category == 'science']))\n",
    "#world_words = clean(' '.join(df.clean[df.category == 'world']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this split function later to create in-sample and out-of-sample datasets for modeling\n",
    "def split(df, stratify_by=None):\n",
    "    \"\"\"\n",
    "    3 way split for train, validate, and test datasets\n",
    "    To stratify, send in a column name\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df[stratify_by])\n",
    "    \n",
    "    train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train[stratify_by])\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data and stratify by category\n",
    "train, validate, test = split(df, 'category')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X variables\n",
    "X_train = train.clean\n",
    "X_validate = validate.clean\n",
    "X_test = test.clean\n",
    "\n",
    "# Setup our y variables\n",
    "y_train = train.category\n",
    "y_validate = validate.category\n",
    "y_test = test.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "technology       25\n",
       "entertainment    25\n",
       "world            25\n",
       "business         25\n",
       "sports           25\n",
       "science          24\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Establish baseline\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the tfidf vectorizer object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "#Fit the object on the training data\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "#Use the object\n",
    "X_train_vectorized =tfidf.transform(X_train)\n",
    "X_validate_vectorized =tfidf.transform(X_validate) \n",
    "X_test_vectorized =tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the vectorized data, make a logistic regression model\n",
    "lm = LogisticRegression()\n",
    "\n",
    "#Fit the lm object to the vectorized data\n",
    "lm.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create corresponding dataframes for the actual values of the categories that correspond to each article\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form predictions uisng the lm model\n",
    "train['predicted'] = lm.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_vectorized)\n",
    "test['predicted'] = lm.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      1.00      1.00        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "      science       0.86      0.92      0.89        13\n",
      "       sports       1.00      1.00      1.00        14\n",
      "   technology       1.00      0.93      0.96        14\n",
      "        world       0.93      0.93      0.93        14\n",
      "\n",
      "     accuracy                           0.96        83\n",
      "    macro avg       0.96      0.96      0.96        83\n",
      " weighted avg       0.97      0.96      0.96        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the lm model performed on the in-sample data\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.25      0.33      0.29         6\n",
      "entertainment       0.62      0.83      0.71         6\n",
      "      science       1.00      0.50      0.67         6\n",
      "       sports       0.50      0.50      0.50         6\n",
      "   technology       0.67      0.67      0.67         6\n",
      "        world       0.60      0.50      0.55         6\n",
      "\n",
      "     accuracy                           0.56        36\n",
      "    macro avg       0.61      0.56      0.56        36\n",
      " weighted avg       0.61      0.56      0.56        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the lm model performed on the out-of-sample data\n",
    "print(classification_report(val- \n",
    "                            idate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "- The lm model performed better on the validate data than the test data for predicting science articles\n",
    "- Overall, the lm model was best able to predict technology articles with 67% accuracy\n",
    "- The lm model was not effective at predicting business articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the KNN object with a k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "#Fit the object to the vectorized training data\n",
    "knn.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Create corresponding dataframes for the actual values of the categories that correspond to each article\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_vectorized)\n",
    "test['predicted'] = knn.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.63      0.86      0.73        14\n",
      "entertainment       0.71      0.86      0.77        14\n",
      "      science       0.73      0.62      0.67        13\n",
      "       sports       0.67      0.71      0.69        14\n",
      "   technology       0.88      0.50      0.64        14\n",
      "        world       0.69      0.64      0.67        14\n",
      "\n",
      "     accuracy                           0.70        83\n",
      "    macro avg       0.72      0.70      0.69        83\n",
      " weighted avg       0.72      0.70      0.69        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the knn model performed on the in-sample data\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.22      0.33      0.27         6\n",
      "entertainment       0.43      0.50      0.46         6\n",
      "      science       0.60      0.50      0.55         6\n",
      "       sports       0.50      0.33      0.40         6\n",
      "   technology       0.60      0.50      0.55         6\n",
      "        world       0.33      0.33      0.33         6\n",
      "\n",
      "     accuracy                           0.42        36\n",
      "    macro avg       0.45      0.42      0.43        36\n",
      " weighted avg       0.45      0.42      0.43        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the knn model performed on the out-of-sample data\n",
    "print(classification_report(validate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "- The KNN model was best able to predict the category for science and tech articles\n",
    "- Business predictions were still the worst\n",
    "- Overall, the KNN model performed worst that the logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the KNN model do with a higher k? k = 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the KNN object with a k = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "\n",
    "#Fit the object to the vectorized training data\n",
    "knn.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Create corresponding dataframes for the actual values of the categories that correspond to each article\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_vectorized)\n",
    "test['predicted'] = knn.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.45      0.64      0.53        14\n",
      "entertainment       0.67      0.71      0.69        14\n",
      "      science       0.82      0.69      0.75        13\n",
      "       sports       0.58      0.79      0.67        14\n",
      "   technology       0.71      0.36      0.48        14\n",
      "        world       0.73      0.57      0.64        14\n",
      "\n",
      "     accuracy                           0.63        83\n",
      "    macro avg       0.66      0.63      0.63        83\n",
      " weighted avg       0.66      0.63      0.62        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the knn model performed on the in-sample data\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.45      0.83      0.59         6\n",
      "entertainment       0.44      0.67      0.53         6\n",
      "      science       1.00      0.67      0.80         6\n",
      "       sports       1.00      0.50      0.67         6\n",
      "   technology       0.75      0.50      0.60         6\n",
      "        world       0.60      0.50      0.55         6\n",
      "\n",
      "     accuracy                           0.61        36\n",
      "    macro avg       0.71      0.61      0.62        36\n",
      " weighted avg       0.71      0.61      0.62        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the knn model performed on the out-of-sample data\n",
    "print(classification_report(validate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "- Overall, the KNN model with k = 10 performed better than the logistic model\n",
    "    - It also performed better at predicting business articles than the any of the previous models on out of sample data\n",
    "- KNN with k = 10 did not perform better than logistic model for predicting ent articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the RF object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=15, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.93\n"
     ]
    }
   ],
   "source": [
    "#Fit the RF object to the training data\n",
    "rf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Predict on y\n",
    "y_pred = rf.predict(X_train_vectorized)\n",
    "\n",
    "#Evaluate\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train_vectorized, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.93      1.00      0.97        14\n",
      "entertainment       1.00      0.93      0.96        14\n",
      "      science       0.90      0.69      0.78        13\n",
      "       sports       0.93      1.00      0.97        14\n",
      "   technology       0.88      1.00      0.93        14\n",
      "        world       0.93      0.93      0.93        14\n",
      "\n",
      "     accuracy                           0.93        83\n",
      "    macro avg       0.93      0.92      0.92        83\n",
      " weighted avg       0.93      0.93      0.92        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.28      0.83      0.42         6\n",
      "entertainment       0.50      0.17      0.25         6\n",
      "      science       1.00      0.33      0.50         6\n",
      "       sports       1.00      0.17      0.29         6\n",
      "   technology       0.30      0.50      0.37         6\n",
      "        world       0.33      0.17      0.22         6\n",
      "\n",
      "     accuracy                           0.36        36\n",
      "    macro avg       0.57      0.36      0.34        36\n",
      " weighted avg       0.57      0.36      0.34        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using out of sample data\n",
    "y_pred = rf.predict(X_validate_vectorized)\n",
    "\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "- RF does not do well, even when changing may depth and min_sample_leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate Model Performance Using the Best Performing Model on the Validate DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.40      0.80      0.53         5\n",
      "entertainment       1.00      0.40      0.57         5\n",
      "      science       1.00      0.80      0.89         5\n",
      "       sports       0.44      0.80      0.57         5\n",
      "   technology       0.50      0.40      0.44         5\n",
      "        world       0.00      0.00      0.00         5\n",
      "\n",
      "     accuracy                           0.53        30\n",
      "    macro avg       0.56      0.53      0.50        30\n",
      " weighted avg       0.56      0.53      0.50        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the KNN object with a k = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "\n",
    "#Fit the object to the vectorized training data\n",
    "knn.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Create corresponding dataframes for the actual values of the categories that correspond to each article\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_vectorized)\n",
    "test['predicted'] = knn.predict(X_test_vectorized)\n",
    "\n",
    "#Review how the knn model performed on the out-of-sample data\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "- The KNN model with a k = 10 accurately predicts ent and science articles 100% of the time.\n",
    "- It does not perform as well as the model did on the validate data for ther other categories and it has a accuracy of 0% for classifying world articles.\n",
    "- All in all, it does do better than just a shot in the dark, which is the equivalent of the baseline model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
